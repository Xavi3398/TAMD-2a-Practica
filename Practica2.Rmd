---
title: "Tècniques Avançades en Mineria de Dades. Pràctica 2"
author:
  - Víctor Rubert Alfonso
  - Francesc Xavier Gayà Morey
output:
  html_notebook:
    df_print: paged
editor_options: 
  markdown: 
    wrap: 72
---

## 1. Preparació del DataFrame

Importar llibreries:

```{r, warning=FALSE}
library(unbalanced)
library(rpart)
library(rpart.plot)
library(caret)
```

### 1.1. Lectura del CSV

Llegir el CSV amb la informació dels crims comesos a Los Ángeles:

```{r}
credit.card = read.csv2("creditcard.csv", header = TRUE, sep = ",")

# Convertir a dades numèriques
for (i in 1:(ncol(credit.card)-1)){
  credit.card[[i]] = as.numeric(credit.card[[i]])
}
credit.card$Class = factor(credit.card$Class, levels = c(0, 1))
```

### Anàlisi exploratori de les variables

```{r}
str(credit.card)
```

```{r}
head(credit.card)
```


#### Desbalanç de les classes

```{r}
n_classes = table(credit.card$Class)
print(paste("Classe 0:", n_classes[[1]], "(", round(n_classes[[1]]*100/sum(n_classes), 3), "%)"))
print(paste("Classe 1:", n_classes[[2]], "(", round(n_classes[[2]]*100/sum(n_classes), 3), "%)"))
```

#### Columna de temps
```{r}
summary(credit.card$Time)
```

```{r}
hist(credit.card$Time, breaks = 100)
```

#### Columna de quantitat
```{r}
summary(credit.card$Amount)
```

```{r}
hist(credit.card$Amount, breaks = 100)
```
Aproximació a funció power-law

#### Resta de columnes

Resum per variable:
```{r}
summary(credit.card[,2:29])
```
Resum de totes a la vegada:
```{r}
summary(c(t(credit.card[,2:29])))
```
Histograma de dues variables a mode d'exemple:
```{r}
hist(credit.card$V13, breaks = 100)
```

```{r}
hist(credit.card$V9, breaks = 100)
```

Pareix que totes les variables s'assimilen a una distribució normal, amb diferent mitjana i variança.


### Separar en conjunts d'Entrenament i Test
```{r}
set.seed(777)
train_ind <- sample(seq_len(nrow(credit.card)), size = floor(nrow(credit.card)*0.8), replace = FALSE)

credit.train <- credit.card[train_ind, ]
credit.test <- credit.card[-train_ind, ]

nrow(credit.train)
table(credit.train$Class)
nrow(credit.test)
table(credit.test$Class)
```


## Model de classificació

```{r}
df_resultats <- function(resultats, gt, nom.tipus.tecnica, nom.tecnica){
  
  arbre = rpart( Class ~ ., data = resultats)
  prediccio = predict(arbre, newdata = credit.test)
  
  df = df_metriques(prediccio, resultats, gt, nom.tipus.tecnica, nom.tecnica, "arbre")
  
  return(df)
}

df_metriques <- function(prediccio, resultats, gt, nom.tipus.tecnica, nom.tecnica, nom.model){
  
  pred_qual = get_pred_qual(prediccio)
  
  # Mètriques
  sensit = sensitivity(pred_qual, gt)
  specif = specificity(pred_qual, gt)
  balanced_acc = (sensit + specif) / 2
  taula_classes = table(resultats$Class)
  
  df = data.frame(
    Tipus.Tecnica = nom.tipus.tecnica,
    Tecnica = nom.tecnica,
    Model = nom.model,
    N.Pos = taula_classes[[2]],
    N.Neg = taula_classes[[1]],
    F1.Measure = F_meas(pred_qual, gt),
    Bal.Acc = balanced_acc,
    Precision = precision(pred_qual, gt),
    Recall = recall(pred_qual, gt),
    Sensitivity = sensit,
    Specificity = specif
  )
  
  return(df)
}

get_pred_qual <- function(prediccion){
  pred_qual=rep("0",dim(prediccion)[1])
  pred_qual[prediccion[,2]>=0.5]="1"
  return(as.factor(pred_qual))
}

print_metrics <- function(prediccion, gt, cm=FALSE){
  pred_qual = get_pred_qual(prediccion)
  if(cm)
    print(confusionMatrix(data = pred_qual, gt))
  else{
    pred_qual = get_pred_qual(prediccion)
    sensit = sensitivity(pred_qual, gt)
    specif = specificity(pred_qual, gt)
    balanced_acc = (sensit + specif) / 2
  
    print(paste("F1-measure:", F_meas(pred_qual, gt)))
    print(paste("Balanced Accuracy:", balanced_acc))
    print(paste("Sensitivity:", sensit))
    print(paste("Specificity:", specif))
  }
}

# Funció per ajuntar X i Y dels resultats en un sol DataFrame:
to_dataframe <- function(results) {
  new_df = results$X
  new_df$Class = results$Y
  return(new_df)
}
```


```{r}
df.resultats = df_resultats(credit.train, credit.test$Class, "Cap", "Cap")
df.resultats
```

```{r}
arbol = rpart(Class ~ ., data = credit.train)
specificity(get_pred_qual(predict(arbol, newdata = credit.test)), credit.test$Class)
df.prova = df_resultats(to_dataframe(results), credit.test$Class, "Cap", "1")

df.prova
```


## Rebalanceig de les dades

### Undersampling

* Random
* Tomek Links
* Condensed Nearest Neighbors (CNN)
* Edited Nearest Neighbors (ENN)
* Neighborhood Cleaning Rule (NCL)
* One-Sided Detection (OSS): Tomek Links + CNN
* CNN + Tomek Links

#### Condensed Nearest Neighbors (CNN)
```{r}
results = ubCNN(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, k=1)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "CNN"))
```

#### Tomek Links
```{r}
results = ubTomek(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "TL"))
```

#### One-Sided Detection (OSS): Tomek Links + CNN
```{r}
results = ubOSS(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "TL+CNN"))
```
#### Neighborhood Cleaning Rule (NCL)
```{r}
results = ubNCL(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, k=3) # Amb k=10 no n'esborra cap
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "NCL"))
```

#### Edited Nearest Neighbors (ENN)
```{r}
results = ubENN(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, k=3)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "ENN"))
```

#### Random
```{r}
results = ubUnder(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, perc = 30)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "R.Under"))
```

#### CNN + Tomek Links
```{r}
cnn2 = ubCNN(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, k=1)
results = ubTomek(X=cnn2$X, Y=cnn2$Y)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "CNN+TL"))
```

#### CNN + Tomek Links + Random
```{r}
cnn2 = ubCNN(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, k=1)
tl2 = ubTomek(X=cnn2$X, Y=cnn2$Y)
results = ubUnder(X=tl2$X, Y=tl2$Y, perc = 30)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "CNN+TL+R.Under"))
```

#### Random + CNN + Tomek Links
```{r}
random = ubUnder(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, perc = 30)
cnn2 = ubCNN(X=random$X, Y=random$Y, k=1)
results = ubTomek(X=cnn2$X, Y=cnn2$Y)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Undersampling", "R.Under+CNN+TL"))
```


### Oversampling

* Random
* SMOTE
* Borderline-SMOTE -> no està al paquet unbalanced

#### Random
```{r}
# Emprar k=0 per deixar amb els mateixos exemples que classe majoritària
results = ubOver(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, k = 300)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Oversampling", "R.Over"))
```



#### SMOTE

```{r}
results = rbind(credit.train, to_dataframe(ubSMOTE(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, perc.over = 20000, perc.under = 0)))
df.resultats = rbind(df.resultats, df_resultats(results, credit.test$Class, "Oversampling", "SMOTE"))
```

### Hybrid resampling

* SMOTE with random undersampling
* SMOTE + Tomek LInks
* SMOTE + ENN
* Altres combinacions

#### SMOTE with random undersampling
```{r}
results = ubSMOTE(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, perc.over = 20000, perc.under = 200)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Hybrid Resampling", "SMOTE+R.Under"))
```

#### SMOTE + Tomek LInks
```{r}
h.smote.tk = join.smote.results(ubSMOTE(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, perc.over = 20000, perc.under = 0), credit.train)
results = ubTomek(X=h.smote.tk[, -ncol(credit.train)], Y=h.smote.tk$Class)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Hybrid Resampling", "SMOTE+TK"))
```

#### SMOTE + ENN
```{r}
h.smote.enn = join.smote.results(ubSMOTE(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, perc.over = 20000, perc.under = 0), credit.train)
results = ubENN(X=h.smote.enn[, -ncol(credit.train)], Y=h.smote.enn$Class, k=3)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Hybrid Resampling", "SMOTE+ENN"))
```

#### SMOTE with random undersampling + Tomek Links
```{r}
h.urandom.smote.tk = ubSMOTE(X=credit.train[, -ncol(credit.train)], Y=credit.train$Class, perc.over = 2000, perc.under = 200)
results = ubTomek(X=h.urandom.smote.tk$X, Y=h.urandom.smote.tk$Y)
df.resultats = rbind(df.resultats, df_resultats(to_dataframe(results), credit.test$Class, "Hybrid Resampling", "SMOTE+R.Under+TK"))
```

### Model sensible al cost


## Resultats
```{r}
options(digits=5)
df.resultats
```






```{r}
train(Class ~ ., data = credit.train,
                   method = "knn",
                   tuneGrid = data.frame(k=3),
                   metric = "Accuracy")

```

```{r}
library(traineR)

modelo.knn <- train.knn(Class ~ ., credit.train, ks=c(3))
p <- predict(modelo.knn, credit.test, type = "class")
```
















